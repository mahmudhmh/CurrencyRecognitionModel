{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CurrencyRecognitionModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNUE2M2qoq/R4ERvtpH3CWu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahmudhmh/CurrencyRecognitionModel/blob/main/CurrencyRecognitionModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvjjrNnhtVZT"
      },
      "outputs": [],
      "source": [
        "pip install tensorflow==2.1.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.python.keras import layers\n",
        "from tensorflow.python.keras.models import Model\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "from tensorflow.keras.layers import Dense,GlobalAveragePooling2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "from tensorflow.keras.layers import Dropout\n",
        "import numpy as np\n",
        "from IPython.display import Image\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Accessing My Google Drive\n",
        "drive.mount('/content/drive')  # access my drive"
      ],
      "metadata": {
        "id": "Y6j5BZvktg-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install keras\n"
      ],
      "metadata": {
        "id": "1_8cj3QztoDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import os\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "NyKu6vn6tqMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_size=(256,256) #provided by network resizing"
      ],
      "metadata": {
        "id": "HAZPAWrjtuhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bast5dm el swar 3shan a3mlha zoom in w out w rescale 3shan a5od mnha kol el positions \n",
        "#ll validation w el training\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=40,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,)\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "e1BQoE-ztwrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ba2sm el swar w b7dd el directory bt3o w b7dd el batch size \n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    validation_split=0.2) # set validation split\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/MyDrive/Adv MM Project',\n",
        "    target_size=target_size,\n",
        "    color_mode='rgb',\n",
        "    batch_size=64,\n",
        "    class_mode='categorical',\n",
        "    subset='training') # set as training data\n",
        "\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/My Drive/Adv MM Project', # same directory as training data\n",
        "    target_size=target_size,\n",
        "    color_mode='rgb',\n",
        "    batch_size=64,\n",
        "    class_mode='categorical',\n",
        "    subset='validation') # set as validation data"
      ],
      "metadata": {
        "id": "fgWIM_8ztzuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator.image_shape "
      ],
      "metadata": {
        "id": "DlhcYXeet2O8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator.class_indices #bcheck 3la el classes el training"
      ],
      "metadata": {
        "id": "VssCB4eFt45B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "   tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=(256,256,3)),\n",
        "   tf.keras.layers.MaxPool2D(\n",
        "    pool_size=(2, 2)),\n",
        "   tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "   tf.keras.layers.MaxPool2D(\n",
        "    pool_size=(2, 2)),\n",
        "   tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "   tf.keras.layers.MaxPool2D(\n",
        "    pool_size=(2, 2)),\n",
        "    \n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(rate=0.5),\n",
        "     tf.keras.layers.Dense(7, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "USm0_clquCJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "img1 = image.load_img('/content/drive/My Drive/Data/Five/Egypt_5_obverse.jpg')\n",
        "plt.imshow(img1);\n",
        "#preprocess image\n",
        "img1 = image.load_img('/content/drive/My Drive/Data/Five/Egypt_5_obverse.jpg', target_size=(256, 256))\n",
        "img = image.img_to_array(img1)\n",
        "img = img/255\n",
        "img = np.expand_dims(img, axis=0)"
      ],
      "metadata": {
        "id": "agDDisUkuGSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "INIT_LR = 1e-3\n",
        "BS = 32"
      ],
      "metadata": {
        "id": "PtA7mJIFuJBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])\n",
        "# Adam optimizer\n",
        "# loss function will be categorical cross entropy\n",
        "# evaluation metric will be accuracy"
      ],
      "metadata": {
        "id": "p3Wqod28uLB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "iyD-C-IFuNhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=train_generator.samples//train_generator.batch_size,\n",
        "        epochs=20,\n",
        "        validation_data=validation_generator,\n",
        "        validation_steps=validation_generator.samples//validation_generator.batch_size)"
      ],
      "metadata": {
        "id": "rPxit2YcuOwa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "accuracy = history.history['accuracy']\n",
        "val_accuracy = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(accuracy) + 1)\n",
        "#Train and validation accuracy\n",
        "plt.plot(epochs, accuracy, 'b', label='Training accurarcy')\n",
        "plt.plot(epochs, val_accuracy, 'r', label='Validation accurarcy')\n",
        "plt.title('Training and Validation accurarcy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "#Train and validation loss\n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6YA4CNhGuTcF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import load_model\n",
        "model.save('CurrencyRecognitionModel.h5')"
      ],
      "metadata": {
        "id": "hw0jj4LZuXDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('CurrencyRecognitionModel_weights.h5')"
      ],
      "metadata": {
        "id": "qaNbUF8tudB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get classes of model trained on\n",
        "classes = train_generator.class_indices \n",
        "classes"
      ],
      "metadata": {
        "id": "PJHIfyLYujZq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Classes = [\"One\",\"Five\",\"Ten\",\"Twenty\",\"Fifty\",\"Hundred\",\"TwoHundred\"]"
      ],
      "metadata": {
        "id": "2MxeJKQsulmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Pre-Processing test data same as train data.\n",
        "img_width=256\n",
        "img_height=256\n",
        "\n",
        "\n",
        "from keras.preprocessing import image\n",
        "\n",
        "def prepare(img_path):\n",
        "    img = image.load_img(img_path, target_size=(256, 256))\n",
        "    x = image.img_to_array(img)\n",
        "    x = x/255\n",
        "    return np.expand_dims(x, axis=0)\n",
        "    \n",
        "    \n",
        "result = model.predict_classes([prepare('/content/drive/My Drive/Data/One/One 0.jpg')])\n",
        "Currency=image.load_img('/content/drive/My Drive/Data/One/One 0.jpg')\n",
        "plt.imshow(Currency)\n",
        "print (Classes[int(result)])"
      ],
      "metadata": {
        "id": "JMrOp7c3uv2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Pre-Processing test data same as train data.\n",
        "img_width=256\n",
        "img_height=256\n",
        "#model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "from keras.preprocessing import image\n",
        "\n",
        "def prepare(img_path):\n",
        "    img = image.load_img(img_path, target_size=(256, 256))\n",
        "    x = image.img_to_array(img)\n",
        "    x = x/255\n",
        "    return np.expand_dims(x, axis=0)\n",
        "    \n",
        "    \n",
        "result = model.predict_classes([prepare('/content/drive/My Drive/Data/Five/Five 0.jpg')])\n",
        "Currency=image.load_img('/content/drive/My Drive/Data/Five/Five 0.jpg')\n",
        "plt.imshow(Currency)\n",
        "print (Classes[int(result)])"
      ],
      "metadata": {
        "id": "gU4s7gZTu-zo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-Processing test data same as train data.\n",
        "img_width=256\n",
        "img_height=256\n",
        "#model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "from keras.preprocessing import image\n",
        "\n",
        "def prepare(img_path):\n",
        "    img = image.load_img(img_path, target_size=(256, 256))\n",
        "    x = image.img_to_array(img)\n",
        "    x = x/255\n",
        "    return np.expand_dims(x, axis=0)\n",
        "    \n",
        "    \n",
        "result = model.predict_classes([prepare('/content/drive/My Drive/Data/Ten/10 front.jpg')])\n",
        "Currency=image.load_img('/content/drive/My Drive/Data/Ten/10 front.jpg')\n",
        "plt.imshow(Currency)\n",
        "print (Classes[int(result)])"
      ],
      "metadata": {
        "id": "MWUxgs7ovB_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-Processing test data same as train data.\n",
        "img_width=256\n",
        "img_height=256\n",
        "#model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "from keras.preprocessing import image\n",
        "\n",
        "def prepare(img_path):\n",
        "    img = image.load_img(img_path, target_size=(256, 256))\n",
        "    x = image.img_to_array(img)\n",
        "    x = x/255\n",
        "    return np.expand_dims(x, axis=0)\n",
        "    \n",
        "    \n",
        "result = model.predict_classes([prepare('/content/drive/My Drive/Data/Twenty/20 front.jpg)])\n",
        "Currency=image.load_img('/content/drive/My Drive/Data/Twenty/20 front.jpg')\n",
        "plt.imshow(Currency)\n",
        "print (Classes[int(result)])"
      ],
      "metadata": {
        "id": "ksMVHV6QvPWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-Processing test data same as train data.\n",
        "img_width=256\n",
        "img_height=256\n",
        "#model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "from keras.preprocessing import image\n",
        "\n",
        "def prepare(img_path):\n",
        "    img = image.load_img(img_path, target_size=(256, 256))\n",
        "    x = image.img_to_array(img)\n",
        "    x = x/255\n",
        "    return np.expand_dims(x, axis=0)\n",
        "    \n",
        "    \n",
        "result = model.predict_classes([prepare('/content/drive/My Drive/Data/Fifty/50 front.jpg')])\n",
        "Currency=image.load_img('/content/drive/My Drive/Data/Fifty/50 front.jpg')\n",
        "plt.imshow(Currency)\n",
        "print (Classes[int(result)])"
      ],
      "metadata": {
        "id": "UgU6uWB7vSmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-Processing test data same as train data.\n",
        "img_width=256\n",
        "img_height=256\n",
        "#model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "from keras.preprocessing import image\n",
        "\n",
        "def prepare(img_path):\n",
        "    img = image.load_img(img_path, target_size=(256, 256))\n",
        "    x = image.img_to_array(img)\n",
        "    x = x/255\n",
        "    return np.expand_dims(x, axis=0)\n",
        "    \n",
        "    \n",
        "result = model.predict_classes([prepare('/content/drive/My Drive/Data/Hundred/100 front.jpg')])\n",
        "Currency=image.load_img('/content/drive/My Drive/Data/Hundred/100 front.jpg')\n",
        "plt.imshow(Currency)\n",
        "print (Classes[int(result)])"
      ],
      "metadata": {
        "id": "tqx8dDf9vY7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pre-Processing test data same as train data.\n",
        "img_width=256\n",
        "img_height=256\n",
        "#model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "from keras.preprocessing import image\n",
        "\n",
        "def prepare(img_path):\n",
        "    img = image.load_img(img_path, target_size=(256, 256))\n",
        "    x = image.img_to_array(img)\n",
        "    x = x/255\n",
        "    return np.expand_dims(x, axis=0)\n",
        "    \n",
        "    \n",
        "result = model.predict_classes([prepare('/content/drive/My Drive/Data/TwoHundred/200 Front.jpg')])\n",
        "Currency=image.load_img('/content/drive/My Drive/Data/TwoHundred/200 Front.jpg')\n",
        "plt.imshow(Currency)\n",
        "print (Classes[int(result)])"
      ],
      "metadata": {
        "id": "G96wO0S2vh6-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}